{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"18rkSkRTmAckj0IY_F1bECyyc5b9KhNda","timestamp":1679695678659}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Read before running\n","\n","- Make a copy of this Colab and save it to your personal folder for the project\n","- Save 'mbti_allLabledAuthors.csv' to you project folder. You can find it in my project folder which is shared with you.\n","- make a folder called ‘mbti_users_scrape’ in your project folder\n","- **DON’T** copy my author_log.csv file, the code will make your own in your project folder\n","- Change the 'my_dir' variable to match the path to your personal project folder.\n","- Change the start & end idx variables to match your assigned range (written in a comment below). \n","- You should now be able to run the notebook\n","- If your collar session times out, refer to the author_log file and the last cell in this notebook to find the index of the last author you scraped. That number rounded up to the nearest 100 will be your new starting index"],"metadata":{"id":"1lP46W3KzApE"}},{"cell_type":"code","source":["# Mount your google drive so you can read/write files\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"kUjjzM54AAlQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t49JSk39STgi","executionInfo":{"status":"ok","timestamp":1679675221330,"user_tz":240,"elapsed":14384,"user":{"displayName":"Luis Ruiz","userId":"02721672642318796029"}},"outputId":"47c398a7-0777-4c4f-ed61-d81330a30f1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pmaw\n","  Downloading pmaw-3.0.0-py3-none-any.whl (29 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.4.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from pmaw) (2.27.1)\n","Collecting praw\n","  Downloading praw-7.7.0-py3-none-any.whl (189 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.4/189.4 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from pandas) (1.22.4)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Collecting prawcore<3,>=2.1\n","  Downloading prawcore-2.3.0-py3-none-any.whl (16 kB)\n","Collecting websocket-client>=0.54.0\n","  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting update-checker>=0.18\n","  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->pmaw) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->pmaw) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->pmaw) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->pmaw) (1.26.15)\n","Installing collected packages: websocket-client, update-checker, prawcore, praw, pmaw\n","Successfully installed pmaw-3.0.0 praw-7.7.0 prawcore-2.3.0 update-checker-0.18.0 websocket-client-1.5.1\n"]}],"source":["#install the library to scrape pushshift\n","!pip install pmaw pandas"]},{"cell_type":"code","source":["from pmaw import PushshiftAPI\n","import pandas as pd\n","import numpy as np\n","from datetime import datetime, timedelta\n","import unicodedata as ud\n","from itertools import product\n","import os\n","\n","def format_df(df_original, authors_df, author):\n","  df = df_original.copy()\n","  # Remove partial matches\n","  df = df[df['author']== author]\n","  # Add 'author_flair_text' column to the comment dataframe\n","  df['author_flair_text'] = authors_df.loc[authors_df['author'] == author, 'author_flair_text'].iloc[0]\n","  # Keep only relevant columns\n","  df = df[['author','author_flair_text','body', 'subreddit']]\n","  # filter out posts in mbti subreddits\n","  blacklist = [''.join(tup) for tup in list(product(['e', 'i'],['s', 'n'], ['f', 't'],['j', 'p']))]\n","  blacklist.append('mbti')\n","  df['subreddit'] = df['subreddit'].apply(lambda x: x.lower())\n","  for sub in blacklist:\n","    df = df[df.subreddit != sub]\n","  # Clean the comment text\n","  df['body'] = df['body'].apply(clean_comment)\n","  return df\n","\n","def clean_comment(comment):\n","  # to filter for empty comments\n","  if type(comment) == str:\n","    # Keep alphanumeric characters, spaces, and common punctuation marks and symbols\n","    allowed_chars = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 !\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n","    comment = ''.join([c for c in comment if c in allowed_chars])\n","    # Standardize alphanumeric characters using the unicodedata library\n","    comment = ''.join([ud.normalize('NFKD', c).encode('ASCII', 'ignore').decode() for c in comment])\n","  else:\n","    comment = np.nan\n","  return comment\n","\n","######## Path to your personal project folder########\n","my_dir = '/content/drive/MyDrive/Classes/EECS_448/Project/' # fill in\n","####################################################\n","\n","# read authors dataframe\n","path = os.path.join(my_dir, 'mbti_allLabledAuthors.csv')\n","authors_df = pd.read_csv(path, usecols=['author', 'author_flair_text'])\n","\n","# Initialize pushshift api instance\n","api = PushshiftAPI()\n","\n","# Define scrape window\n","start_date = datetime(2022, 11, 3)\n","end_date = datetime(2023, 3, 21)\n","\n","# Initialize empty list to store comment dataframes\n","comment_dfs = []\n","comment_count = 0\n","\n","# Define starting index for the scrapping session\n","# LR:(0-3700), JS:(3701-6200), AS:(6201-8700), JY:(8701-11022)\n","start_idx = 3701 # based on the author log\n","end_idx = 6201 # based on numbers above, +1 because of how range() works\n","\n","# Loop over unique authors in the dataframe\n","for i in range(start_idx, end_indx):\n","  # find author from index\n","  author = authors_df.loc[i].author\n","  # Use PMAW to search for comments by this author\n","  comments = api.search_comments(author=author, \n","                                  since = int(start_date.timestamp()),\n","                                  until = int(end_date.timestamp()),\n","                                  limit=1000,\n","                                  safe_exit=True\n","                                  )\n","  # Some users might have no activity, so we need try/except to avoid erroring out\n","  try:\n","    # Convert comment data to a Pandas dataframe\n","    comment_df = pd.DataFrame(comments)\n","    # Format df\n","    comment_df = format_df(comment_df, authors_df, author)\n","    # Append the comment dataframe to the list\n","    comment_dfs.append(comment_df)\n","  except:\n","    pass\n","  #Save a file every 100 authors (~20min)\n","  if i % 100 == 0:\n","    print(i)\n","    # Merge df of last 100 authors in to a single df\n","    comments_df = pd.concat(comment_dfs, ignore_index=True)\n","    # Update the comment count, note that this number resets evreytime you restart the colab session\n","    comment_count += len(comments_df.index)\n","    # Save scraped comments of past 100 authors to csv file\n","    fname = os.path.join(my_dir,'mbti_users_scrape/authors_{}_{}totalComments.csv'.format(i, comment_count))\n","    comments_df.to_csv(fname)\n","    # Make log of past 100 authors scraped\n","    log = comments_df.drop_duplicates(subset='author')\n","    # Append usernames of past 100 authors to csv file tracking scraped authors\n","    log_path=os.path.join(my_dir,'author_log.csv')\n","    log.to_csv(log_path, mode=('w' if i==0 else 'a'), columns=['author'], header=(True if i==0 else False))\n","    # empty list storing author dfs\n","    comment_dfs = []  "],"metadata":{"id":"1UsgtV-vxjh6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use this line and the last username in your author_log.csv file to find what your starting index should be\n","authors_df[authors_df['author']=='Ok-Reporter-196']\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"YN_Qx3HwcgTJ","executionInfo":{"status":"ok","timestamp":1679687161045,"user_tz":240,"elapsed":162,"user":{"displayName":"Luis Ruiz","userId":"02721672642318796029"}},"outputId":"51bed672-3b62-4549-a7a6-c9555b29fe67"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               author author_flair_text\n","1199  Ok-Reporter-196              enfj"],"text/html":["\n","  <div id=\"df-4a49f59d-0c76-456f-8002-33732c4bf15b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author</th>\n","      <th>author_flair_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1199</th>\n","      <td>Ok-Reporter-196</td>\n","      <td>enfj</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a49f59d-0c76-456f-8002-33732c4bf15b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4a49f59d-0c76-456f-8002-33732c4bf15b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4a49f59d-0c76-456f-8002-33732c4bf15b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]}]}